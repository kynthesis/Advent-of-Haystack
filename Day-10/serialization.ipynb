{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI Api key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MessagePack is an efficient binary serialization format. It's not supposed to be human-readable, as you can see:\n",
    "ancient_instructions = b'\\x84\\xa8metadata\\x80\\xb1max_loops_allowedd\\xaacomponents\\x86\\xa9converter\\x82\\xa4type\\xd92haystack.components.converters.html.HTMLToDocument\\xafinit_parameters\\x80\\xa7fetcher\\x82\\xa4type\\xd9<haystack.components.fetchers.link_content.LinkContentFetcher\\xafinit_parameters\\x84\\xb0raise_on_failure\\xc3\\xabuser_agents\\x91\\xd9#haystack/LinkContentFetcher/0.152.0\\xaeretry_attempts\\x02\\xa7timeout\\x03\\xa3llm\\x82\\xa4type\\xd92haystack.components.generators.openai.OpenAIGenerator\\xafinit_parameters\\x85\\xaamodel_name\\xadgpt-3.5-turbo\\xb2streaming_callback\\xc0\\xacapi_base_url\\xb9https://api.openai.com/v1\\xb1generation_kwargs\\x80\\xadsystem_prompt\\xc0\\xaeprompt_builder\\x82\\xa4type\\xd99haystack.components.builders.prompt_builder.PromptBuilder\\xafinit_parameters\\x81\\xa8template\\xd9\\x8a Acc  ding to these docu  nts:\\n{% for  oc in documents %}  {{ doc.con     }} {% endfor %}\\nAnswer the given qu  tion: {{question}} Answer: \\xa6ranker\\x82\\xa4type\\xd9Phaystack.components.rankers.transformers_similarity.TransformersSimilarityRanker\\xafinit_parameters\\x84\\xa6device\\xa3cpu\\xb2model_name_or_path\\xd9$cross-encoder/ms-marco-MiniLM-L-6-v2\\xa5token\\xc0\\xa5top_k\\x03\\xa8splitter\\x82\\xa4type\\xd9Dhaystack.components.preprocessors.document_splitter.DocumentSplitter\\xafinit_parameters\\x83\\xa8split_by\\xa4word\\xacsplit_length2\\xadsplit_overlap\\x00\\xabconnections\\x95\\x82\\xa6sender\\xb3converter.documents\\xa8receiver\\xb2splitter.documents\\x82\\xa6sender\\xaffetcher.streams\\xa8receiver\\xb1converter.sources\\x82\\xa6sender\\xb5prompt_builder.prompt\\xa8receiver\\xaallm.prompt\\x82\\xa6sender\\xb0ranker.documents\\xa8receiver\\xb8prompt_builder.documents\\x82\\xa6sender\\xb2splitter.documents\\xa8receiver\\xb0ranker.documents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Union\n",
    "import msgpack\n",
    "\n",
    "\n",
    "class MsgpackMarshaller:\n",
    "    \"\"\"\n",
    "    Custom Messagepack marshaller implementing\n",
    "    the Marshaller protocol in Haystack.\n",
    "    \"\"\"\n",
    "    def marshal(self, dict_: Dict[str, Any]) -> str:\n",
    "        return msgpack.dumps(dict_)\n",
    "\n",
    "    def unmarshal(self, data_: Union[str, bytes]) -> Dict[str, Any]:\n",
    "        return dict(msgpack.loads(data_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "pipe = Pipeline.loads(ancient_instructions, MsgpackMarshaller())\n",
    "print(pipe.dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_pipeline_definition = \"\"\"\n",
    "components:\n",
    "  converter:\n",
    "    init_parameters: {}\n",
    "    type: haystack.components.converters.html.HTMLToDocument\n",
    "  fetcher:\n",
    "    init_parameters:\n",
    "      raise_on_failure: true\n",
    "      retry_attempts: 2\n",
    "      timeout: 3\n",
    "      user_agents:\n",
    "      - haystack/LinkContentFetcher/0.152.0\n",
    "    type: haystack.components.fetchers.link_content.LinkContentFetcher\n",
    "  llm:\n",
    "    init_parameters:\n",
    "      api_base_url: https://api.openai.com/v1\n",
    "      generation_kwargs: {}\n",
    "      model: gpt-3.5-turbo\n",
    "      streaming_callback: null\n",
    "      system_prompt: null\n",
    "    type: haystack.components.generators.openai.OpenAIGenerator\n",
    "  prompt_builder:\n",
    "    init_parameters:\n",
    "      template: ' Acc  ding to these docu  nts:\n",
    "\n",
    "        {% for  oc in documents %}  {{ doc.con     }} {% endfor %}\n",
    "\n",
    "        Answer the given qu  tion: {{question}} Answer: '\n",
    "    type: haystack.components.builders.prompt_builder.PromptBuilder\n",
    "  ranker:\n",
    "    init_parameters:\n",
    "      device: cpu\n",
    "      model_name_or_path: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
    "      token: null\n",
    "      top_k: 3\n",
    "    type: haystack.components.rankers.transformers_similarity.TransformersSimilarityRanker\n",
    "  splitter:\n",
    "    init_parameters:\n",
    "      split_by: word\n",
    "      split_length: 50\n",
    "      split_overlap: 0\n",
    "    type: haystack.components.preprocessors.document_splitter.DocumentSplitter\n",
    "connections:\n",
    "- receiver: splitter.documents\n",
    "  sender: converter.documents\n",
    "- receiver: converter.sources\n",
    "  sender: fetcher.streams\n",
    "- receiver: llm.prompt\n",
    "  sender: prompt_builder.prompt\n",
    "- receiver: prompt_builder.documents\n",
    "  sender: ranker.documents\n",
    "- receiver: ranker.documents\n",
    "  sender: splitter.documents\n",
    "max_loops_allowed: 100\n",
    "metadata: {}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_pipeline_definition = \"\"\"\n",
    "components:\n",
    "  converter:\n",
    "    init_parameters: {}\n",
    "    type: haystack.components.converters.html.HTMLToDocument\n",
    "  fetcher:\n",
    "    init_parameters:\n",
    "      raise_on_failure: true\n",
    "      retry_attempts: 2\n",
    "      timeout: 3\n",
    "      user_agents:\n",
    "      - haystack/LinkContentFetcher/0.152.0\n",
    "    type: haystack.components.fetchers.link_content.LinkContentFetcher\n",
    "  llm:\n",
    "    init_parameters:\n",
    "      api_base_url: https://api.openai.com/v1\n",
    "      generation_kwargs: {}\n",
    "      model: gpt-3.5-turbo\n",
    "      streaming_callback: null\n",
    "      system_prompt: null\n",
    "    type: haystack.components.generators.openai.OpenAIGenerator\n",
    "  prompt_builder:\n",
    "    init_parameters:\n",
    "      template: ' According to these documents:\n",
    "\n",
    "        {% for doc in documents %}  {{ doc.content }} {% endfor %}\n",
    "\n",
    "        Answer the given qu  tion: {{question}} Answer: '\n",
    "    type: haystack.components.builders.prompt_builder.PromptBuilder\n",
    "  ranker:\n",
    "    init_parameters:\n",
    "      device: cpu\n",
    "      model_name_or_path: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
    "      token: null\n",
    "      top_k: 3\n",
    "    type: haystack.components.rankers.transformers_similarity.TransformersSimilarityRanker\n",
    "  splitter:\n",
    "    init_parameters:\n",
    "      split_by: word\n",
    "      split_length: 50\n",
    "      split_overlap: 0\n",
    "    type: haystack.components.preprocessors.document_splitter.DocumentSplitter\n",
    "connections:\n",
    "- receiver: splitter.documents\n",
    "  sender: converter.documents\n",
    "- receiver: converter.sources\n",
    "  sender: fetcher.streams\n",
    "- receiver: llm.prompt\n",
    "  sender: prompt_builder.prompt\n",
    "- receiver: prompt_builder.documents\n",
    "  sender: ranker.documents\n",
    "- receiver: ranker.documents\n",
    "  sender: splitter.documents\n",
    "max_loops_allowed: 100\n",
    "metadata: {}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "working_pipeline = Pipeline.loads(fixed_pipeline_definition)\n",
    "result = working_pipeline.run({\n",
    "    \"prompt_builder\": {\"question\": \"how do I start a lathe?\"},\n",
    "    \"ranker\": {\"query\": \"how do I start a lathe?\"},\n",
    "    \"fetcher\": {\"urls\": [\"https://en.wikipedia.org/wiki/Lathe\"]}\n",
    "})\n",
    "print(result[\"llm\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
