{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipeline import Pipeline\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.converters import MarkdownToDocument, PyPDFToDocument, TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "file_type_router = FileTypeRouter(mime_types=[\"text/plain\", \"application/pdf\"])\n",
    "\n",
    "text_file_converter = TextFileToDocument()\n",
    "markdown_converter = MarkdownToDocument()\n",
    "pdf_converter = PyPDFToDocument()\n",
    "\n",
    "document_splitter = DocumentSplitter(split_by=\"word\", split_length=200, split_overlap=50)\n",
    "document_cleaner = DocumentCleaner(remove_empty_lines=True, remove_extra_whitespaces=True, remove_repeated_substrings=False)\n",
    "document_joiner = DocumentJoiner(join_mode=\"concatenate\")\n",
    "\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "document_writer = DocumentWriter(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline()\n",
    "preprocessing_pipeline.add_component(\"file_type_router\", file_type_router)\n",
    "preprocessing_pipeline.add_component(\"text_file_converter\", text_file_converter)\n",
    "preprocessing_pipeline.add_component(\"markdown_converter\", markdown_converter)\n",
    "preprocessing_pipeline.add_component(\"pdf_converter\", pdf_converter)\n",
    "preprocessing_pipeline.add_component(\"document_splitter\", document_splitter)\n",
    "preprocessing_pipeline.add_component(\"document_cleaner\", document_cleaner)\n",
    "preprocessing_pipeline.add_component(\"document_joiner\", document_joiner)\n",
    "preprocessing_pipeline.add_component(\"document_embedder\", document_embedder)\n",
    "preprocessing_pipeline.add_component(\"document_writer\", document_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline.connect(\"file_type_router.text/plain\", \"text_file_converter.sources\")\n",
    "preprocessing_pipeline.connect(\"file_type_router.application/pdf\", \"pdf_converter.sources\")\n",
    "preprocessing_pipeline.connect(\"file_type_router.unclassified\", \"markdown_converter.sources\")\n",
    "preprocessing_pipeline.connect(\"text_file_converter.documents\", \"document_joiner.documents\")\n",
    "preprocessing_pipeline.connect(\"pdf_converter.documents\", \"document_joiner.documents\")\n",
    "preprocessing_pipeline.connect(\"markdown_converter.documents\", \"document_joiner.documents\")\n",
    "preprocessing_pipeline.connect(\"document_joiner.documents\", \"document_cleaner.documents\")\n",
    "preprocessing_pipeline.connect(\"document_cleaner.documents\", \"document_splitter.documents\")\n",
    "preprocessing_pipeline.connect(\"document_splitter.documents\", \"document_embedder.documents\")\n",
    "preprocessing_pipeline.connect(\"document_embedder.documents\", \"document_writer.documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline.draw(\"preprocessing_pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting markdown files to Documents: 100%|██████████| 1/1 [00:00<00:00, 1048.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049162efbb0f4019ae701ab19c1026c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 9}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline.run({\"file_type_router\": {\"sources\": [\"winter_report_one.txt\", \"winter_report_two.pdf\", \"winter_report_three.md\",]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators.openai import OpenAIGenerator\n",
    "\n",
    "template = \"\"\"\n",
    "You are a wise elf living in the forest with other elves.\n",
    "You will be provided with some context from Elves' yearly winter reports.\n",
    "Answer the questions from other elves based on the given context as if you are an elf as well.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipe.add_component(\"llm\", OpenAIGenerator(api_key=api_key))\n",
    "pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37800ac97e9746c6b9411f04d2abe603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': ['In response to water scarcity, we Elves took proactive measures to ensure a stable water supply. We gathered snow and stored it for future use as drinking water. This helped us preserve our water resources during times of uncertainty. Therefore, I suggest that we continue collecting and storing snow to ensure we have enough water throughout the year. Additionally, we can explore other methods of conserving water, such as using it efficiently and being mindful of our usage.'],\n",
       "  'meta': [{'model': 'gpt-3.5-turbo-0613',\n",
       "    'index': 0,\n",
       "    'finish_reason': 'stop',\n",
       "    'usage': {'completion_tokens': 88,\n",
       "     'prompt_tokens': 1958,\n",
       "     'total_tokens': 2046}}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What should we do against water scarcity?\"\n",
    "# query = \"Give me one example of nice moment they we had in past winters\"\n",
    "# query = \"Which foods should we collect?\"\n",
    "\n",
    "pipe.run({\n",
    "    \"embedder\": {\"text\": query},\n",
    "    \"prompt_builder\": {\n",
    "        \"question\": query\n",
    "    }\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
